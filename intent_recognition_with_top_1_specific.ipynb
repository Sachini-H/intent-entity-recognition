{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whj88oSB2214"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7_O5wGsA6Pv"
      },
      "source": [
        "This code example employs a sliding window mechanism which would keep the last three user prompts as-is but summarizes everything before that and uses the as-is messages AND teh summary to dynamically predict the direction the conversation is heading. Note that we can tweak the sliding window length and retain more messages in their original form if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMXMXJGrxkg0"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "from typing import List, Optional\n",
        "import json\n",
        "import re\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07FzblXxsqY"
      },
      "outputs": [],
      "source": [
        "# I am using Gpt-4o model\n",
        "client = openai.OpenAI(api_key=\"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\")\n",
        "model = \"gpt-4o\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNYuqwLEBbxR"
      },
      "outputs": [],
      "source": [
        "window_length = 3\n",
        "max_tokens_summary = 1000\n",
        "max_tokens_total = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_ttzchl-nRG"
      },
      "outputs": [],
      "source": [
        "# Define Enum type for initial context\n",
        "class OfficeContextType(Enum):\n",
        "    OFFICE = \"OFFICE\"\n",
        "    NON_OFFICE = \"NON-OFFICE\"\n",
        "    NEUTRAL = \"NEUTRAL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwYeeD73-ngs"
      },
      "outputs": [],
      "source": [
        "# Define office realted prompts intent types\n",
        "class OfficeIntentType(Enum):\n",
        "    PURCHASE_OFFICE_EQUIPMENT = \"PURCHASE_OFFICE_SUPPLIES\"\n",
        "    CLIENT_DINNER = \"CLIENT_DINNER\"\n",
        "    TRANSPORTATION_EXPENSE = \"TRANSPORATION_EXPENSE\"\n",
        "    ACCOMADATION_EXPENSE = \"ACCOMADATION_EXPENSE\"\n",
        "    AFTERPARTY_EXPENSE = \"AFTERPARTY_EXPENSE\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RSekah7-nn8"
      },
      "outputs": [],
      "source": [
        "# Define roles in the chat\n",
        "class UserRole(Enum):\n",
        "    assistant = \"assistant\"\n",
        "    system = \"system\"\n",
        "    user = \"user\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ4Bf_-9-nyX"
      },
      "outputs": [],
      "source": [
        "# Define a message into the LLM\n",
        "class Messages(BaseModel):\n",
        "    id: str\n",
        "    content: str\n",
        "    role: UserRole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zW0-iD0_gnJ"
      },
      "outputs": [],
      "source": [
        "# Recive a list of messages (actually a slice of all messages) and summarize them\n",
        "def summarize_messages(messages: List[Messages]) -> str:\n",
        "\n",
        "    content = \" \".join([f\"{msg.role.value}: {msg.content}\" for msg in messages])\n",
        "\n",
        "    summary_prompt = f\"Summarize the following conversation: {content}\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "        max_tokens=max_tokens_summary,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVnDXX9A_34j"
      },
      "outputs": [],
      "source": [
        "def generate_office_intent_prompt( summary: str, recent_messages: List[Messages]):\n",
        "\n",
        "    recent_content = \"\\n\".join([f\"{msg.role.value}: {msg.content}\" for msg in recent_messages])\n",
        "\n",
        "    allowed_context_types = json.dumps([context_type.value for context_type in OfficeContextType])\n",
        "\n",
        "    allowed_intent_types = json.dumps([intent_type.value for intent_type in OfficeIntentType])\n",
        "\n",
        "    return f\"\"\"\n",
        "    You are an expert corporate financial assistant.\n",
        "    Based on the summarized context and recent user messages,\n",
        "    predict the user's intent and provide reasoning.\n",
        "\n",
        "    # Instructions\n",
        "    1. The list of allowed 'officeIntentType' values are: {allowed_context_types} .\n",
        "    2. Use the 'officeContextType' to determine what type of 'context' the user is in.\n",
        "    3. Based on the 'officeContextType', context summary and recent conversation\n",
        "     determine the 'officeIntentTypes'.\n",
        "    4. The list of allowed 'officeIntentType' values are: {allowed_intent_types}\n",
        "    5. If the user_query is uncertain, unclear, or irrelevant, use 'GENERAL_INQUIRY'\n",
        "     as the default intent.\n",
        "    7. Add a clear description why you detected these reason why you detected these officeIntentTypes. This would be the reasoning. Use 10-15 words.\n",
        "    8. Now summarize the reasoning and add that as title.Use 5 words.\n",
        "    9. Order the list of officeIntentType from most likely to least likely for the most recent message and provide only the top 1.\n",
        "\n",
        "\n",
        "    Return JSON: {{\"officeIntent\": [{{\"officeContextType\": \"officeContextType\", \"officeIntentType\": [\"officeIntentType\"], \"reasoning\": \"reasoning\", \"title\": title}}]}}\n",
        "\n",
        "    # Context Summary\n",
        "    {summary}\n",
        "\n",
        "    # Recent Conversation\n",
        "    {recent_content}\n",
        "\n",
        "\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwopMEJjATKH"
      },
      "outputs": [],
      "source": [
        "async def predict_office_intent(messages: List[Messages]):\n",
        "\n",
        "    # Summarize all except recent 3 messages\n",
        "    summary = summarize_messages(messages[:window_length])\n",
        "    # Sliding window for last 3 messages\n",
        "    recent_messages = messages[-window_length:]\n",
        "\n",
        "    # Determine office context (Overly simplified version for now, anything with a content is office-related)\n",
        "    #office_context_type = OfficeContextType.NON_OFFICE if not recent_messages else OfficeContextType.OFFICE\n",
        "\n",
        "    prompt = generate_office_intent_prompt(summary, recent_messages)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens_total,\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].message.content\n",
        "    cleaned_content = re.sub(r'```json|\\n|```', '', response_text).strip()\n",
        "\n",
        "    return cleaned_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgCLbBEBAukw"
      },
      "outputs": [],
      "source": [
        "# Function to iteratively handle messages and print responses\n",
        "async def handle_conversation():\n",
        "    messages = []\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Add user message to history\n",
        "        messages.append(Messages(id=str(len(messages)+1), content=user_input, role=UserRole.user))\n",
        "\n",
        "        # Get the intent detection result\n",
        "        response = await predict_office_intent(messages)\n",
        "\n",
        "        # Print each detected intent\n",
        "        print(\"Detected Intent:\")\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4yUEZSk0VQ0",
        "outputId": "7b7c6b95-8b25-4e10-9673-9d9920ea7d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Intent:\n",
            "{  \"officeIntent\": [    {      \"officeContextType\": \"OFFICE\",      \"officeIntentType\": [\"AFTERPARTY_EXPENSE\"],      \"reasoning\": \"User needs to entertain clients after a conference, indicating afterparty expenses.\",      \"title\": \"Client entertainment after conference\"    }  ]}\n"
          ]
        }
      ],
      "source": [
        "# Run the conversation handler\n",
        "await handle_conversation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY_XXKhXrSNN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouvyXGobrSQF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWC_q3V4rSSZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c66WK6OFrSVN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGLEtsJPrSYj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}